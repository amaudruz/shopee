{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import functools\n",
    "from functools import partial\n",
    "import PIL\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DistilBertModel\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train val split\n",
    "labels = np.random.permutation(df['label_group'].unique())\n",
    "\n",
    "train_perc = 0.7\n",
    "train_idx = int(train_perc * len(labels))\n",
    "\n",
    "train_labels = labels[:train_idx]\n",
    "val_labels = labels[train_idx:]\n",
    "\n",
    "train_df = df[df['label_group'].isin(train_labels)]\n",
    "val_df = df[df['label_group'].isin(val_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a756327777b2fe8e9383ab84468f3e5a',\n",
       " 'c58ef3697a5ae269fc16a6d3d4b56877',\n",
       " '05f1bc3c03271e5d4b5af7a7b263facf',\n",
       " '2826339257579760a00d6e0a0065a89e',\n",
       " '451b108436f28c18b2dc8bf63b712c08',\n",
       " '2f5c66fc9bb86bc81dd461cc6ad574e1',\n",
       " 'cbd375037243af186a4aa8d3aa08a489',\n",
       " '4edcfc239c17445eb949103c9f13eed3',\n",
       " '67e712eb6d5b08c0eb9e074cd7cc71c4',\n",
       " '712782879a3ef3acbb0c8eb945335528']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "images_path = 'data/train_images/'\n",
    "image_ids = [s.split('.')[0] for s in os.listdir(images_path)]\n",
    "image_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset) :\n",
    "    def __init__(self, images_path, df, img_tfms, testing, text_tokenizer=None):\n",
    "        super(TripletDataset, self).__init__()\n",
    "        \n",
    "        self.images_path = images_path\n",
    "        self.img_tfms = img_tfms\n",
    "        self.testing = testing\n",
    "              \n",
    "        self.df = df.copy()\n",
    "        self.df['label_group'] = self.df['label_group'].astype('category').cat.codes\n",
    "        self.df['index'] = range(self.df.shape[0])\n",
    "        self.labels = self.df['label_group'].unique()\n",
    "        self.label_to_index_list = self.df.groupby('label_group')['index'].apply(list)\n",
    "        \n",
    "    def __getitem__(self, index) :\n",
    "        index_meta = self.df.iloc[index]\n",
    "        \n",
    "        anchor_image, anchor_text = self._get_item(index)\n",
    "        \n",
    "        if self.testing: return anchor_image, anchor_text\n",
    "        \n",
    "        label = index_meta['label_group']\n",
    "        \n",
    "        # positive sample\n",
    "        pos_index = random.choice(self.label_to_index_list[label])\n",
    "        # we don't want the positive sample being the same as the anchor\n",
    "        while pos_index == index :\n",
    "            pos_index = random.choice(self.label_to_index_list[label])\n",
    "        pos_image, pos_text = self._get_item(pos_index)\n",
    "        \n",
    "        #negative sample\n",
    "        neg_label = random.choice(self.labels)\n",
    "        # Negative sample has to be different label from anchor \n",
    "        while neg_label == index :\n",
    "            neg_label = random.choice(self.labels)\n",
    "        neg_index = random.choice(self.label_to_index_list[neg_label])\n",
    "        neg_image, neg_text = self._get_item(neg_index)\n",
    "        \n",
    "        return anchor_image, anchor_text, pos_image, pos_text, neg_image, neg_text\n",
    "        \n",
    "    def _get_item(self, index) :\n",
    "        image = PIL.Image.open(os.path.join(self.images_path, \n",
    "                                            self.df.iloc[index]['image']))\n",
    "        image = self.img_tfms(image)\n",
    "        text = self.df.iloc[index]['title']\n",
    "        return image, text\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(tokenizer, samples) :\n",
    "    batch_size = len(samples)\n",
    "    if len(samples[0]) == 2:\n",
    "        images, texts = zip(*samples)\n",
    "        images = torch.stack(images)\n",
    "        texts = tokenizer(list(texts), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        return images, texts\n",
    "    anchor_images, anchor_texts, pos_images, pos_texts, neg_images, neg_texts = zip(*samples)\n",
    "    anchor_images = torch.stack(anchor_images)\n",
    "    pos_images = torch.stack(pos_images)\n",
    "    neg_images = torch.stack(neg_images)\n",
    "    anchor_texts = tokenizer(list(anchor_texts), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    pos_texts = tokenizer(list(pos_texts), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    neg_texts = tokenizer(list(neg_texts), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return anchor_images, anchor_texts, pos_images, pos_texts, neg_images, neg_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dl(images_path, df_paths, img_tfms, pretrianed_tokenizer='distilbert-base-uncased', \n",
    "              batch_size=64, shuffle = True, testing = False) :\n",
    "    dataset = TripletDataset(images_path, df_paths, img_tfms, testing)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrianed_tokenizer)\n",
    "    dl = DataLoader(dataset, batch_size=batch_size, collate_fn=partial(collate_fn, tokenizer), \n",
    "                    shuffle = shuffle, pin_memory = True)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedorNN(nn.Module) :\n",
    "    def __init__(self, pretrained_image_embedor='resnet18', pretrained_text_embedor='distilbert-base-uncased',\n",
    "                output_dim=128) :\n",
    "        super(EmbedorNN, self).__init__()\n",
    "        self.image_embedor = timm.create_model(pretrained_image_embedor, pretrained=True)\n",
    "        self.image_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.text_embedor = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.head = nn.Linear(512+768, output_dim)\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        images, texts = x\n",
    "        out_images = self.image_embedor.forward_features(images)\n",
    "        out_images = self.image_pool(out_images).squeeze()\n",
    "        out_text = self.text_embedor(texts['input_ids'], \n",
    "                                     attention_mask=texts['attention_mask'])[0][:,0,:]\n",
    "        out = torch.cat([out_images, out_text], dim=-1)\n",
    "        return F.normalize(self.head(out), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = nn.Sequential(nn.Linear(256, 30), nn.ReLU(), nn.Dropout(0.1), nn.Linear(30,1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initweights(module):\n",
    "    \"\"\" Initialize the weights \"\"\"\n",
    "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "        sz = module.weight.data.size(-1)\n",
    "        module.weight.data.normal_(mean=0.0, std=1/np.sqrt(sz))\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        module.bias.data.zero()\n",
    "        module.weight.data.fill(1.0)\n",
    "    elif isinstance(module, nn.Conv2d):\n",
    "        n = module.kernel_size[0] * module.kernel_size[1] * module.out_channels\n",
    "        module.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "        module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in cls.parameters():\n",
    "    initweights(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                 std=(0.229, 0.224, 0.225))\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize((250, 250)),\n",
    "                                       transforms.ColorJitter(.25,.25,.25),\n",
    "                                       transforms.RandomRotation(5),\n",
    "                                       transforms.RandomCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       normalize\n",
    "                                       ])\n",
    "\n",
    "val_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     normalize\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbedorNN().to(device)\n",
    "# weights: https://drive.google.com/drive/folders/19BGTC53p5YIAakWeCZfNIsceMX7cjHgp?usp=sharing\n",
    "#model.load_state_dict(torch.load('3ep.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dl = create_dl(images_path, train_df, train_transforms, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dl = create_dl(images_path, val_df, val_transforms, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dl = create_dl(images_path, df, val_transforms, shuffle = False, testing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "swa_start = int(0.75*n_epochs)\n",
    "\n",
    "lf = nn.TripletMarginLoss()\n",
    "lf2 = nn.BCEWithLogitsLoss()\n",
    "\n",
    "lr = 1e-4\n",
    "wd = 1e-3\n",
    "no_decay = [\"bias\", \"BatchNorm2d.weight\", \"BatchNorm2d.bias\", \"LayerNorm.weight\", 'LayerNorm.bias']\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)] + [p for n, p in cls.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": wd,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in  model.named_parameters() if any(nd in n for nd in no_decay)] + [p for n, p in  cls.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "\n",
    "# learning rate scheduler\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr =lr, pct_start = 0.3, #anneal_strategy = 'linear',\n",
    "                                            total_steps = int(n_epochs * len(tr_dl)))\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83f70ce57474c7593894fee32c015cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c8f080453443208e8e6d4f9bfe88cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd4be9f88f04928a443864c4c37d9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 0: Tr triplet 0.076, bce 0.659 - Val triplet 0.022, bce 0.632\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1d0c72dc4243169a3eb566c07a2d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5535851c220e471091bc3a70bb84636b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Tr triplet 0.021, bce 0.603 - Val triplet 0.024, bce 0.542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa4ee34f01f4541a44cb44571286f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f59251d7e142ca825a1ddec729d827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Tr triplet 0.018, bce 0.497 - Val triplet 0.017, bce 0.417\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9968c03355624546b9095b344e016fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fc1c45847c4d9cb0b06ccb5f52edd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3: Tr triplet 0.011, bce 0.392 - Val triplet 0.013, bce 0.348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad68fbdd0fd74ccdb8be6e14f37545c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd6de078b0545ebacf4d44ee7bb7425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b82cd7e14aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0manchor_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchor_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             anchor = anchor_image.to(device), {'input_ids' : anchor_text['input_ids'].to(device),\n",
      "\u001b[0;32m~/Documents/3plus/3penv/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3plus/3penv/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3plus/3penv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3plus/3penv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3plus/3penv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3plus/3penv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-310e856ca00b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mneg_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mneg_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_to_index_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneg_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mneg_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0manchor_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchor_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-310e856ca00b>\u001b[0m in \u001b[0;36m_get_item\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     42\u001b[0m         image = PIL.Image.open(os.path.join(self.images_path, \n\u001b[1;32m     43\u001b[0m                                             self.df.iloc[index]['image']))\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_tfms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3plus/3penv/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3plus/3penv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3plus/3penv/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3plus/3penv/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \"\"\"\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3plus/3penv/lib/python3.8/site-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3plus/3penv/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3plus/3penv/lib/python3.8/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tr_triplet_losses = []\n",
    "tr_bce_losses = []\n",
    "val_triplet_losses = []\n",
    "val_bce_losses = []\n",
    "for ep in tqdm(range(n_epochs)):\n",
    "    cls.train()\n",
    "    model.train()\n",
    "    tr_triplet_loss = []\n",
    "    tr_bce_loss = []\n",
    "    pbar = tqdm(tr_dl)\n",
    "    for anchor_image, anchor_text, pos_image, pos_text, neg_image, neg_text in pbar:\n",
    "        \n",
    "        \n",
    "        anchor = anchor_image.to(device), {'input_ids' : anchor_text['input_ids'].to(device),\n",
    "                                           'attention_mask' : anchor_text['attention_mask'].to(device)}\n",
    "        \n",
    "        pos = pos_image.to(device), {'input_ids' : pos_text['input_ids'].to(device),\n",
    "                                     'attention_mask' : pos_text['attention_mask'].to(device)}\n",
    "        \n",
    "        neg = neg_image.to(device), {'input_ids' : neg_text['input_ids'].to(device),\n",
    "                                     'attention_mask' : neg_text['attention_mask'].to(device)}\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            anchor_emb = model(anchor)\n",
    "            pos_emb = model(pos)\n",
    "            neg_emb = model(neg)\n",
    "            triplet_loss = lf(anchor_emb, pos_emb, neg_emb)\n",
    "            \n",
    "            pos_samples_1 = torch.cat([anchor_emb, pos_emb],-1)\n",
    "            pos_samples_2 = torch.cat([pos_emb, anchor_emb],-1)\n",
    "\n",
    "            neg_samples_11 = torch.cat([anchor_emb, neg_emb],-1)\n",
    "            neg_samples_12 = torch.cat([neg_emb, anchor_emb],-1)\n",
    "\n",
    "            neg_samples_21 = torch.cat([pos_emb, neg_emb],-1)\n",
    "            neg_samples_22 = torch.cat([neg_emb, pos_emb],-1)\n",
    "\n",
    "            x = torch.cat([pos_samples_1, pos_samples_2, \n",
    "                           neg_samples_11, neg_samples_12,\n",
    "                           neg_samples_21, neg_samples_22],0)\n",
    "\n",
    "            y = torch.cat([torch.ones(2*len(pos_samples_1)), \n",
    "                               torch.zeros(2*(len(neg_samples_11) \n",
    "                                              + len(neg_samples_21)))],0)[:,None].to(device)\n",
    "            out = cls(x)\n",
    "            bce_loss = lf2(out,y)\n",
    "            \n",
    "        scaler.scale(triplet_loss + bce_loss*0.2).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        sched.step()\n",
    "        \n",
    "        tr_triplet_loss.append(triplet_loss.item())\n",
    "        tr_bce_loss.append(bce_loss.item())\n",
    "        pbar.set_description(f\"Tr triplet: {round(np.mean(tr_triplet_loss),3)}, bce: {round(np.mean(tr_bce_loss),3)}\")\n",
    "        \n",
    "    model.eval()\n",
    "    cls.eval()\n",
    "    val_triplet_loss = []\n",
    "    val_bce_loss = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_dl)\n",
    "        for anchor_image, anchor_text, pos_image, pos_text, neg_image, neg_text in pbar:\n",
    "\n",
    "            anchor = anchor_image.to(device), {'input_ids' : anchor_text['input_ids'].to(device),\n",
    "                                               'attention_mask' : anchor_text['attention_mask'].to(device)}\n",
    "\n",
    "            pos = pos_image.to(device), {'input_ids' : pos_text['input_ids'].to(device),\n",
    "                                         'attention_mask' : pos_text['attention_mask'].to(device)}\n",
    "\n",
    "            neg = neg_image.to(device), {'input_ids' : neg_text['input_ids'].to(device),\n",
    "                                         'attention_mask' : neg_text['attention_mask'].to(device)}\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                \n",
    "                anchor_emb = model(anchor)\n",
    "                pos_emb = model(pos)\n",
    "                neg_emb = model(neg)\n",
    "                triplet_loss = lf(anchor_emb, pos_emb, neg_emb)\n",
    "                \n",
    "                pos_samples_1 = torch.cat([anchor_emb, pos_emb],-1)\n",
    "                pos_samples_2 = torch.cat([pos_emb, anchor_emb],-1)\n",
    "                \n",
    "                neg_samples_11 = torch.cat([anchor_emb, neg_emb],-1)\n",
    "                neg_samples_12 = torch.cat([neg_emb, anchor_emb],-1)\n",
    "                \n",
    "                neg_samples_21 = torch.cat([pos_emb, neg_emb],-1)\n",
    "                neg_samples_22 = torch.cat([neg_emb, pos_emb],-1)\n",
    "                \n",
    "                x = torch.cat([pos_samples_1, pos_samples_2, \n",
    "                               neg_samples_11, neg_samples_12,\n",
    "                               neg_samples_21, neg_samples_22],0)\n",
    "                \n",
    "                y = torch.cat([torch.ones(2*len(pos_samples_1)), \n",
    "                               torch.zeros(2*(len(neg_samples_11) \n",
    "                                              + len(neg_samples_21)))],0)[:,None].to(device)\n",
    "                out = cls(x)\n",
    "                bce_loss = lf2(out,y)\n",
    "\n",
    "            val_triplet_loss.append(triplet_loss.item())\n",
    "            val_bce_loss.append(bce_loss.item())\n",
    "            pbar.set_description(f\"Val triplet: {round(np.mean(val_triplet_loss),3)}, bce: {round(np.mean(val_bce_loss),3)}\")\n",
    "            \n",
    "    tr_triplet_loss = round(np.mean(tr_triplet_loss),3)\n",
    "    val_triplet_loss = round(np.mean(val_triplet_loss),3)\n",
    "    tr_triplet_losses.append(tr_triplet_loss)\n",
    "    val_triplet_losses.append(val_triplet_loss)\n",
    "    \n",
    "    tr_bce_loss = round(np.mean(tr_bce_loss),3)\n",
    "    val_bce_loss = round(np.mean(val_bce_loss),3)\n",
    "    tr_bce_losses.append(tr_bce_loss)\n",
    "    val_bce_losses.append(val_bce_loss)\n",
    "    summary = f\"Ep {ep}: Tr triplet {tr_triplet_loss}, bce {tr_bce_loss} - Val triplet {val_triplet_loss}, bce {val_bce_loss}\"\n",
    "    print(summary) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '10ep.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa6b2fefc2c43b2a5514766eaeab2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embs = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(testing_dl)\n",
    "    for image, text in pbar:\n",
    "        x = image.to(device), {'input_ids' : text['input_ids'].to(device),\n",
    "                               'attention_mask' : text['attention_mask'].to(device)}\n",
    "        y = model(x)\n",
    "        embs.append(y.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.cat(embs,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_df = pd.DataFrame(embs.numpy())\n",
    "emb_cols = [f'emb_{i}' for i in embs_df.columns]\n",
    "embs_df.columns = emb_cols\n",
    "embs_df['cls'] = df['label_group']\n",
    "embs_df['cls'] = embs_df['cls'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>34240</th>\n",
       "      <th>34241</th>\n",
       "      <th>34242</th>\n",
       "      <th>34243</th>\n",
       "      <th>34244</th>\n",
       "      <th>34245</th>\n",
       "      <th>34246</th>\n",
       "      <th>34247</th>\n",
       "      <th>34248</th>\n",
       "      <th>34249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>emb_0</th>\n",
       "      <td>0.500960</td>\n",
       "      <td>0.237719</td>\n",
       "      <td>0.050669</td>\n",
       "      <td>0.718747</td>\n",
       "      <td>-0.581001</td>\n",
       "      <td>-0.097971</td>\n",
       "      <td>1.183702</td>\n",
       "      <td>1.779962</td>\n",
       "      <td>1.124665</td>\n",
       "      <td>-0.972785</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.564198</td>\n",
       "      <td>0.842688</td>\n",
       "      <td>-0.393273</td>\n",
       "      <td>-0.365358</td>\n",
       "      <td>-0.153456</td>\n",
       "      <td>-0.877197</td>\n",
       "      <td>0.058753</td>\n",
       "      <td>-0.112191</td>\n",
       "      <td>0.031476</td>\n",
       "      <td>0.074278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_1</th>\n",
       "      <td>-1.301394</td>\n",
       "      <td>-1.292176</td>\n",
       "      <td>-0.944553</td>\n",
       "      <td>-1.888656</td>\n",
       "      <td>-0.108013</td>\n",
       "      <td>-0.747545</td>\n",
       "      <td>-1.263595</td>\n",
       "      <td>-1.211068</td>\n",
       "      <td>-0.682983</td>\n",
       "      <td>0.179870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.576654</td>\n",
       "      <td>-0.905915</td>\n",
       "      <td>-0.449244</td>\n",
       "      <td>-0.466996</td>\n",
       "      <td>-0.804786</td>\n",
       "      <td>-0.308678</td>\n",
       "      <td>0.259296</td>\n",
       "      <td>-0.835542</td>\n",
       "      <td>-0.930508</td>\n",
       "      <td>-1.531453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_2</th>\n",
       "      <td>-0.226438</td>\n",
       "      <td>0.306056</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.311137</td>\n",
       "      <td>-0.544753</td>\n",
       "      <td>-0.013903</td>\n",
       "      <td>0.166399</td>\n",
       "      <td>0.306137</td>\n",
       "      <td>0.915265</td>\n",
       "      <td>-0.525376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455988</td>\n",
       "      <td>0.210848</td>\n",
       "      <td>-0.447949</td>\n",
       "      <td>-0.411966</td>\n",
       "      <td>0.376221</td>\n",
       "      <td>-0.085963</td>\n",
       "      <td>0.045716</td>\n",
       "      <td>0.809573</td>\n",
       "      <td>-0.265023</td>\n",
       "      <td>0.909191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_3</th>\n",
       "      <td>-0.323761</td>\n",
       "      <td>0.608568</td>\n",
       "      <td>-0.098363</td>\n",
       "      <td>-1.106508</td>\n",
       "      <td>0.221210</td>\n",
       "      <td>-1.320947</td>\n",
       "      <td>-0.539112</td>\n",
       "      <td>-1.217819</td>\n",
       "      <td>0.357320</td>\n",
       "      <td>-0.854563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597615</td>\n",
       "      <td>-0.977988</td>\n",
       "      <td>1.731781</td>\n",
       "      <td>1.720604</td>\n",
       "      <td>0.479843</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>0.526009</td>\n",
       "      <td>-0.228569</td>\n",
       "      <td>0.531991</td>\n",
       "      <td>0.439010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_4</th>\n",
       "      <td>-1.258861</td>\n",
       "      <td>-0.940595</td>\n",
       "      <td>0.709853</td>\n",
       "      <td>-0.407680</td>\n",
       "      <td>0.241497</td>\n",
       "      <td>-1.016383</td>\n",
       "      <td>-0.178965</td>\n",
       "      <td>-0.405246</td>\n",
       "      <td>0.401834</td>\n",
       "      <td>-0.620351</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.869939</td>\n",
       "      <td>-1.265399</td>\n",
       "      <td>-0.175623</td>\n",
       "      <td>-0.220973</td>\n",
       "      <td>-0.101543</td>\n",
       "      <td>-1.238433</td>\n",
       "      <td>-0.110854</td>\n",
       "      <td>-0.539160</td>\n",
       "      <td>0.548752</td>\n",
       "      <td>-1.179566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_124</th>\n",
       "      <td>1.327470</td>\n",
       "      <td>0.503480</td>\n",
       "      <td>0.680511</td>\n",
       "      <td>0.594233</td>\n",
       "      <td>-0.113412</td>\n",
       "      <td>-0.175654</td>\n",
       "      <td>0.622813</td>\n",
       "      <td>0.947124</td>\n",
       "      <td>0.934831</td>\n",
       "      <td>-0.190990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169104</td>\n",
       "      <td>0.302227</td>\n",
       "      <td>1.240302</td>\n",
       "      <td>1.217515</td>\n",
       "      <td>-0.716665</td>\n",
       "      <td>-0.396859</td>\n",
       "      <td>0.584340</td>\n",
       "      <td>-0.777377</td>\n",
       "      <td>0.648708</td>\n",
       "      <td>-0.493271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_125</th>\n",
       "      <td>-1.127460</td>\n",
       "      <td>-0.561340</td>\n",
       "      <td>0.595688</td>\n",
       "      <td>-0.708277</td>\n",
       "      <td>-0.253344</td>\n",
       "      <td>-1.247321</td>\n",
       "      <td>-0.849796</td>\n",
       "      <td>-1.481531</td>\n",
       "      <td>0.011094</td>\n",
       "      <td>-1.126404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344415</td>\n",
       "      <td>-0.091109</td>\n",
       "      <td>1.479870</td>\n",
       "      <td>1.414771</td>\n",
       "      <td>-0.354530</td>\n",
       "      <td>0.216521</td>\n",
       "      <td>-0.839207</td>\n",
       "      <td>-1.230204</td>\n",
       "      <td>0.316971</td>\n",
       "      <td>-1.293721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_126</th>\n",
       "      <td>0.465477</td>\n",
       "      <td>-1.320146</td>\n",
       "      <td>0.288588</td>\n",
       "      <td>0.464027</td>\n",
       "      <td>0.089630</td>\n",
       "      <td>-0.426252</td>\n",
       "      <td>-0.943907</td>\n",
       "      <td>0.281021</td>\n",
       "      <td>0.681009</td>\n",
       "      <td>0.782818</td>\n",
       "      <td>...</td>\n",
       "      <td>1.783656</td>\n",
       "      <td>0.248377</td>\n",
       "      <td>0.240647</td>\n",
       "      <td>0.235544</td>\n",
       "      <td>0.519699</td>\n",
       "      <td>-0.012075</td>\n",
       "      <td>0.809881</td>\n",
       "      <td>1.609108</td>\n",
       "      <td>-0.025901</td>\n",
       "      <td>-0.320838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_127</th>\n",
       "      <td>1.034373</td>\n",
       "      <td>-0.168213</td>\n",
       "      <td>-0.304716</td>\n",
       "      <td>-0.008191</td>\n",
       "      <td>0.086427</td>\n",
       "      <td>1.383384</td>\n",
       "      <td>0.928859</td>\n",
       "      <td>0.351101</td>\n",
       "      <td>0.364785</td>\n",
       "      <td>0.460414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302482</td>\n",
       "      <td>-0.573974</td>\n",
       "      <td>0.280889</td>\n",
       "      <td>0.266239</td>\n",
       "      <td>-0.264183</td>\n",
       "      <td>-0.374306</td>\n",
       "      <td>1.208320</td>\n",
       "      <td>-0.497938</td>\n",
       "      <td>-0.462315</td>\n",
       "      <td>0.550078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls</th>\n",
       "      <td>666.000000</td>\n",
       "      <td>7572.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>10509.000000</td>\n",
       "      <td>9425.000000</td>\n",
       "      <td>6836.000000</td>\n",
       "      <td>4687.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>6076.000000</td>\n",
       "      <td>6754.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>8761.000000</td>\n",
       "      <td>9200.000000</td>\n",
       "      <td>9200.000000</td>\n",
       "      <td>7971.000000</td>\n",
       "      <td>9735.000000</td>\n",
       "      <td>7038.000000</td>\n",
       "      <td>10537.000000</td>\n",
       "      <td>4242.000000</td>\n",
       "      <td>1163.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 34250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1            2             3            4      \\\n",
       "emb_0      0.500960     0.237719     0.050669      0.718747    -0.581001   \n",
       "emb_1     -1.301394    -1.292176    -0.944553     -1.888656    -0.108013   \n",
       "emb_2     -0.226438     0.306056     0.002641      0.311137    -0.544753   \n",
       "emb_3     -0.323761     0.608568    -0.098363     -1.106508     0.221210   \n",
       "emb_4     -1.258861    -0.940595     0.709853     -0.407680     0.241497   \n",
       "...             ...          ...          ...           ...          ...   \n",
       "emb_124    1.327470     0.503480     0.680511      0.594233    -0.113412   \n",
       "emb_125   -1.127460    -0.561340     0.595688     -0.708277    -0.253344   \n",
       "emb_126    0.465477    -1.320146     0.288588      0.464027     0.089630   \n",
       "emb_127    1.034373    -0.168213    -0.304716     -0.008191     0.086427   \n",
       "cls      666.000000  7572.000000  6172.000000  10509.000000  9425.000000   \n",
       "\n",
       "               5            6            7            8            9      ...  \\\n",
       "emb_0      -0.097971     1.183702     1.779962     1.124665    -0.972785  ...   \n",
       "emb_1      -0.747545    -1.263595    -1.211068    -0.682983     0.179870  ...   \n",
       "emb_2      -0.013903     0.166399     0.306137     0.915265    -0.525376  ...   \n",
       "emb_3      -1.320947    -0.539112    -1.217819     0.357320    -0.854563  ...   \n",
       "emb_4      -1.016383    -0.178965    -0.405246     0.401834    -0.620351  ...   \n",
       "...              ...          ...          ...          ...          ...  ...   \n",
       "emb_124    -0.175654     0.622813     0.947124     0.934831    -0.190990  ...   \n",
       "emb_125    -1.247321    -0.849796    -1.481531     0.011094    -1.126404  ...   \n",
       "emb_126    -0.426252    -0.943907     0.281021     0.681009     0.782818  ...   \n",
       "emb_127     1.383384     0.928859     0.351101     0.364785     0.460414  ...   \n",
       "cls      6836.000000  4687.000000  3976.000000  6076.000000  6754.000000  ...   \n",
       "\n",
       "              34240        34241        34242        34243        34244  \\\n",
       "emb_0     -1.564198     0.842688    -0.393273    -0.365358    -0.153456   \n",
       "emb_1     -0.576654    -0.905915    -0.449244    -0.466996    -0.804786   \n",
       "emb_2      0.455988     0.210848    -0.447949    -0.411966     0.376221   \n",
       "emb_3      0.597615    -0.977988     1.731781     1.720604     0.479843   \n",
       "emb_4     -0.869939    -1.265399    -0.175623    -0.220973    -0.101543   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "emb_124   -0.169104     0.302227     1.240302     1.217515    -0.716665   \n",
       "emb_125    0.344415    -0.091109     1.479870     1.414771    -0.354530   \n",
       "emb_126    1.783656     0.248377     0.240647     0.235544     0.519699   \n",
       "emb_127   -0.302482    -0.573974     0.280889     0.266239    -0.264183   \n",
       "cls      340.000000  8761.000000  9200.000000  9200.000000  7971.000000   \n",
       "\n",
       "               34245        34246         34247        34248        34249  \n",
       "emb_0      -0.877197     0.058753     -0.112191     0.031476     0.074278  \n",
       "emb_1      -0.308678     0.259296     -0.835542    -0.930508    -1.531453  \n",
       "emb_2      -0.085963     0.045716      0.809573    -0.265023     0.909191  \n",
       "emb_3       0.006830     0.526009     -0.228569     0.531991     0.439010  \n",
       "emb_4      -1.238433    -0.110854     -0.539160     0.548752    -1.179566  \n",
       "...              ...          ...           ...          ...          ...  \n",
       "emb_124    -0.396859     0.584340     -0.777377     0.648708    -0.493271  \n",
       "emb_125     0.216521    -0.839207     -1.230204     0.316971    -1.293721  \n",
       "emb_126    -0.012075     0.809881      1.609108    -0.025901    -0.320838  \n",
       "emb_127    -0.374306     1.208320     -0.497938    -0.462315     0.550078  \n",
       "cls      9735.000000  7038.000000  10537.000000  4242.000000  1163.000000  \n",
       "\n",
       "[129 rows x 34250 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_df.to_csv('train_embs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
