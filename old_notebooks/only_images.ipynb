{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import functools\n",
    "from functools import partial\n",
    "import PIL\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDS(Dataset):\n",
    "    def __init__(self, data, images_path, return_triplet = True):\n",
    "        super().__init__()\n",
    "        self.imgs = data['image'].tolist()\n",
    "        self.unique_labels = data['label_group'].unique().tolist()\n",
    "        self.labels = data['label_group'].tolist()\n",
    "        self.label_to_index_dict = (data.reset_index(drop = True)\n",
    "                                    .groupby('label_group')\n",
    "                                    .apply(lambda x: x.index.tolist())\n",
    "                                    .to_dict())\n",
    "        self.images_path = images_path\n",
    "        self.return_triplet = return_triplet\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # anchor data\n",
    "        anchor_label = self.labels[idx]\n",
    "        anchor_img = self._get_item(idx)\n",
    "        \n",
    "        if not self.return_triplet: return anchor_img\n",
    "        \n",
    "        # neg data\n",
    "        neg_label = np.random.choice(self.unique_labels)\n",
    "        while neg_label == anchor_label:\n",
    "            neg_label = np.random.choice(self.unique_labels)\n",
    "        neg_idx = np.random.choice(self.label_to_index_dict[neg_label])\n",
    "        neg_img = self._get_item(neg_idx)   \n",
    "        \n",
    "        # pos data\n",
    "        pos_idxs = self.label_to_index_dict[anchor_label]\n",
    "        # picking an index not equal to anchor's index\n",
    "        pos_idxs = [o for o in pos_idxs if o != idx]\n",
    "        \n",
    "        if len(pos_idxs) == 0:\n",
    "            # edge case, only 1 sample per label\n",
    "            pos_idxs = [idx]\n",
    "        pos_idx = np.random.choice(pos_idxs)\n",
    "        pos_img = self._get_item(pos_idx)\n",
    "        \n",
    "        return anchor_img, pos_img, neg_img        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def _get_item(self, idx):\n",
    "        im = PIL.Image.open(os.path.join(self.images_path, self.imgs[idx]))\n",
    "        im = torch.tensor(np.array(im) / 255.0, dtype = torch.float).permute(2,0,1)\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "\n",
    "df = pd.read_csv('data/train.csv')\n",
    "small_images_dir = 'data/small_train_images/'\n",
    "np.random.seed(1337)\n",
    "\n",
    "# train val split\n",
    "\n",
    "train_perc = 0.7\n",
    "n_train_examples = int(train_perc * len(df))\n",
    "\n",
    "train_df = df.iloc[:n_train_examples]\n",
    "val_df = df.iloc[n_train_examples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataloaders\n",
    "\n",
    "vision_model = 'resnet50'\n",
    "\n",
    "bs = 16\n",
    "tr_ds = TripletDS(df, small_images_dir)\n",
    "tr_dl = DataLoader(tr_ds, batch_size = bs, shuffle = True, pin_memory = True)\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedorNN(nn.Module) :\n",
    "    def __init__(self, pretrained_image_embedor='resnet50',\n",
    "                output_dim=512) :\n",
    "        super(EmbedorNN, self).__init__()\n",
    "        self.image_embedor = timm.create_model(pretrained_image_embedor, pretrained=True)\n",
    "        self.image_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.head = nn.Sequential(nn.Linear(2048, output_dim), \n",
    "                                  #nn.ReLU(), \n",
    "                                  #nn.Linear(1024, output_dim)\n",
    "                                 )\n",
    "        \n",
    "        for m in self.head.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                sz = m.weight.data.size(-1)\n",
    "                m.weight.data.normal_(mean=0.0, std=1/np.sqrt(sz))\n",
    "            elif isinstance(m, (nn.LayerNorm, nn.BatchNorm1d)):\n",
    "                m.bias.data.zero_()\n",
    "                m.weight.data.fill_(1.0)\n",
    "                m.bias.data.zero_()\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "    def freeze_cnn(self):\n",
    "        for parameter in self.image_embedor.parameters():\n",
    "            parameter.requires_grad = False\n",
    "            \n",
    "    def unfreeze_cnn(self):\n",
    "        for parameter in self.image_embedor.parameters():\n",
    "            parameter.requires_grad = True\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        images = x\n",
    "        out_images = self.image_embedor.forward_features(images)\n",
    "        out_images = self.image_pool(out_images).squeeze()\n",
    "        \n",
    "        return F.normalize(self.head(out_images), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrained resnet  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbedorNN(vision_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_ds = TripletDS(df, small_images_dir, return_triplet = False)\n",
    "testing_dl = DataLoader(testing_ds, batch_size = bs, shuffle = False, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                 std=(0.229, 0.224, 0.225))\n",
    "\n",
    "val_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                     normalize\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b02dd0a8a74b9f9725b9ec1d1d2670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2141.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embs = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(testing_dl)\n",
    "    for image in pbar:\n",
    "        x = val_transforms(image.to(device))\n",
    "        y = model(x)\n",
    "        embs.append(y.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.cat(embs,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_df = pd.DataFrame(embs.numpy())\n",
    "emb_cols = [f'emb_{i}' for i in embs_df.columns]\n",
    "embs_df.columns = emb_cols\n",
    "embs_df.to_csv('data/tests_model_image/train_embs_re50_pretrain.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrained resnet + Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbedorNN(vision_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalize = transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                 std=(0.229, 0.224, 0.225))\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.ColorJitter(.3,.3,.3),\n",
    "                                       transforms.RandomRotation(5),\n",
    "                                       transforms.RandomCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       normalize\n",
    "                                       ])\n",
    "\n",
    "val_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                     normalize\n",
    "                                     ])\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "lf = nn.TripletMarginLoss(0.5)\n",
    "\n",
    "lr = 1e-4\n",
    "wd = 0\n",
    "no_decay = [\"bias\", \"BatchNorm2d.weight\", \"BatchNorm2d.bias\", \"LayerNorm.weight\", 'LayerNorm.bias',\n",
    "            \"BatchNorm1d.weight\", \"BatchNorm1d.bias\"]\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": wd,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in  model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "\n",
    "# learning rate scheduler\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr =lr, pct_start = 0.3, #anneal_strategy = 'linear',\n",
    "                                            total_steps = int(n_epochs * len(tr_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e06eeceeb234d72804aa94686207ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8766ede4b5f74a75b2556bbb25078980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2141.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 640, 640] at entry 0 and [3, 700, 700] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-71727087dd1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0manchor_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0manchor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 640, 640] at entry 0 and [3, 700, 700] at entry 1"
     ]
    }
   ],
   "source": [
    "tr_losses = []\n",
    "val_losses = []\n",
    "for ep in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    tr_loss = []\n",
    "    pbar = tqdm(tr_dl)\n",
    "    for anchor_image, pos_image, neg_image in pbar:\n",
    "        \n",
    "        anchor = train_transforms(anchor_image.to(device))\n",
    "        pos = train_transforms(pos_image.to(device))\n",
    "        neg = train_transforms(neg_image.to(device))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        anchor_emb = model(anchor)\n",
    "        pos_emb = model(pos)\n",
    "        neg_emb = model(neg)\n",
    "        loss = lf(anchor_emb, pos_emb, neg_emb)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sched.step()\n",
    "        \n",
    "        tr_loss.append(loss.item())\n",
    "        pbar.set_description(f\"Train loss: {round(np.mean(tr_loss),3)}\")\n",
    "    \n",
    "    if ep%2==0 :\n",
    "        torch.save(model.state_dict(), 'data/tests_model_image/model_ep_{}.pth'.format(ep))\n",
    "    model.eval()\n",
    "    tr_losses.append(tr_loss)\n",
    "    summary = f\"Ep {ep}: Train loss {tr_loss}\"\n",
    "    print(summary) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbedorNN(\n",
       "  (image_embedor): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (image_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f377fa56a50>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(tr_losses)) , np.asarray(tr_losses).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07925382, 0.03778575, 0.02642849, 0.02201105, 0.02123296,\n",
       "       0.02270963, 0.02353474, 0.02297144, 0.02175142, 0.020127  ,\n",
       "       0.01835453, 0.01796837, 0.01624757, 0.01467402, 0.01321192,\n",
       "       0.01177035, 0.01068123, 0.00934028, 0.00814935, 0.00748574,\n",
       "       0.00653745, 0.00579803, 0.00511126, 0.00413433, 0.00408054,\n",
       "       0.00361694, 0.00340546, 0.00338286, 0.00316007, 0.00312226])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(tr_losses).mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbedorNN(vision_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('data/tests_model_image/model_ep_28.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_ds = TripletDS(df, small_images_dir, return_triplet = False)\n",
    "testing_dl = DataLoader(testing_ds, batch_size = bs, shuffle = False, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1dbdeca4eb40909cb24a8799028e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1071.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embs = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(testing_dl)\n",
    "    for image in pbar:\n",
    "        x = val_transforms(image.to(device))\n",
    "        y = model(x)\n",
    "        embs.append(y.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.cat(embs,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_df = pd.DataFrame(embs.numpy())\n",
    "emb_cols = [f'emb_{i}' for i in embs_df.columns]\n",
    "embs_df.columns = emb_cols\n",
    "embs_df.to_csv('train_embs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_df.to_csv('train_embs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
