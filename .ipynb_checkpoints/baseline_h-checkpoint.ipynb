{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Embedding-training-(triplet-loss)\" data-toc-modified-id=\"Embedding-training-(triplet-loss)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Embedding training (triplet loss)</a></span></li><li><span><a href=\"#Binary-classifier\" data-toc-modified-id=\"Binary-classifier-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Binary classifier</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import functools\n",
    "from functools import partial\n",
    "import PIL\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DistilBertModel\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train val split\n",
    "labels = np.random.permutation(df['label_group'].unique())\n",
    "\n",
    "train_perc = 0.7\n",
    "train_idx = int(train_perc * len(labels))\n",
    "\n",
    "train_labels = labels[:train_idx]\n",
    "val_labels = labels[train_idx:]\n",
    "\n",
    "train_df = df[df['label_group'].isin(train_labels)]\n",
    "val_df = df[df['label_group'].isin(val_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000a68812bc7e98c42888dfb1c07da0',\n",
       " '00039780dfc94d01db8676fe789ecd05',\n",
       " '000a190fdd715a2a36faed16e2c65df7',\n",
       " '00117e4fc239b1b641ff08340b429633',\n",
       " '00136d1cf4edede0203f32f05f660588',\n",
       " '0013e7355ffc5ff8fb1ccad3e42d92fe',\n",
       " '00144a49c56599d45354a1c28104c039',\n",
       " '0014f61389cbaa687a58e38a97b6383d',\n",
       " '0019a3c6755a194cb2e2c12bfc63972e',\n",
       " '001be52b2beec40ddc1d2d7fc7a68f08']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "images_path = 'data/train_images/'\n",
    "image_ids = [s.split('.')[0] for s in os.listdir(images_path)]\n",
    "image_ids[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding training (triplet loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset) :\n",
    "    def __init__(self, images_path, df, img_tfms, testing, text_tokenizer=None):\n",
    "        super(TripletDataset, self).__init__()\n",
    "        \n",
    "        self.images_path = images_path\n",
    "        self.img_tfms = img_tfms\n",
    "        self.testing = testing\n",
    "              \n",
    "        self.df = df.copy()\n",
    "        self.df['label_group'] = self.df['label_group'].astype('category').cat.codes\n",
    "        self.df['index'] = range(self.df.shape[0])\n",
    "        self.labels = self.df['label_group'].unique()\n",
    "        self.label_to_index_list = self.df.groupby('label_group')['index'].apply(list)\n",
    "        \n",
    "    def __getitem__(self, index) :\n",
    "        index_meta = self.df.iloc[index]\n",
    "        \n",
    "        anchor_image, anchor_text = self._get_item(index)\n",
    "        \n",
    "        if self.testing: return anchor_image, anchor_text\n",
    "        \n",
    "        label = index_meta['label_group']\n",
    "        \n",
    "        # positive sample\n",
    "        pos_index = random.choice(self.label_to_index_list[label])\n",
    "        # we don't want the positive sample being the same as the anchor\n",
    "        while pos_index == index :\n",
    "            pos_index = random.choice(self.label_to_index_list[label])\n",
    "        pos_image, pos_text = self._get_item(pos_index)\n",
    "        \n",
    "        #negative sample\n",
    "        neg_label = random.choice(self.labels)\n",
    "        # Negative sample has to be different label from anchor \n",
    "        while neg_label == index :\n",
    "            neg_label = random.choice(self.labels)\n",
    "        neg_index = random.choice(self.label_to_index_list[neg_label])\n",
    "        neg_image, neg_text = self._get_item(neg_index)\n",
    "        \n",
    "        return anchor_image, anchor_text, pos_image, pos_text, neg_image, neg_text\n",
    "        \n",
    "    def _get_item(self, index) :\n",
    "        image = PIL.Image.open(os.path.join(self.images_path, \n",
    "                                            self.df.iloc[index]['image']))\n",
    "        image = self.img_tfms(image)\n",
    "        text = self.df.iloc[index]['title']\n",
    "        return image, text\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dl(images_path, df_paths, img_tfms, pretrianed_tokenizer='distilbert-base-uncased', \n",
    "              batch_size=64, shuffle = True, testing = False) :\n",
    "    dataset = TripletDataset(images_path, df_paths, img_tfms, testing)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrianed_tokenizer)\n",
    "    dl = DataLoader(dataset, batch_size=batch_size, collate_fn=partial(collate_fn, tokenizer), \n",
    "                    shuffle = shuffle, pin_memory = True)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EmbedorNN(nn.Module) :\n",
    "    def __init__(self, pretrained_image_embedor='resnet18', pretrained_text_embedor='distilbert-base-uncased',\n",
    "                output_dim=128) :\n",
    "        super(EmbedorNN, self).__init__()\n",
    "        self.image_embedor = timm.create_model(pretrained_image_embedor, pretrained=True)\n",
    "        self.image_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.text_embedor = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.head = nn.Linear(512+768, output_dim)\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        images, texts = x\n",
    "        out_images = self.image_embedor.forward_features(images)\n",
    "        out_images = self.image_pool(out_images).squeeze()\n",
    "        out_text = self.text_embedor(texts['input_ids'], \n",
    "                                     attention_mask=texts['attention_mask'])[0][:,0,:]\n",
    "        out = torch.cat([out_images, out_text], dim=-1)\n",
    "        return self.head(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                 std=(0.229, 0.224, 0.225))\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize((250, 250)),\n",
    "                                       transforms.ColorJitter(.25,.25,.25),\n",
    "                                       transforms.RandomRotation(5),\n",
    "                                       transforms.RandomCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       normalize\n",
    "                                       ])\n",
    "\n",
    "val_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     normalize\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EmbedorNN().to(device)\n",
    "# weights: https://drive.google.com/drive/folders/19BGTC53p5YIAakWeCZfNIsceMX7cjHgp?usp=sharing\n",
    "model.load_state_dict(torch.load('3ep.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dl = create_dl(images_path, train_df, train_transforms, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dl = create_dl(images_path, val_df, val_transforms, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dl = create_dl(images_path, df, val_transforms, shuffle = False, testing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "swa_start = int(0.75*n_epochs)\n",
    "\n",
    "lf = nn.TripletMarginLoss()\n",
    "\n",
    "lr = 1e-4\n",
    "wd = 1e-3\n",
    "no_decay = [\"bias\", \"BatchNorm2d.weight\", \"BatchNorm2d.bias\", \"LayerNorm.weight\", 'LayerNorm.bias']\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": wd,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in  model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "\n",
    "# learning rate scheduler\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr =lr, pct_start = 0.3, #anneal_strategy = 'linear',\n",
    "                                            total_steps = int(n_epochs * len(tr_dl)))\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c44b0db65b4bb4b8c9a1f15567071e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3167deb50f15495ca47ae57918556f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1632eb6e454d4e53b1f3ddc67d022945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 0: Train loss 0.064 - Val loss 0.023\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8792b030a09844edbac44dc1f12a54c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acbd62bf4214aa0b246667221277b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Train loss 0.018 - Val loss 0.018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0901597420194d4195c59e1aa7718e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afff355d5874467cbe67c32290135600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Train loss 0.008 - Val loss 0.012\n"
     ]
    }
   ],
   "source": [
    "tr_losses = []\n",
    "val_losses = []\n",
    "for ep in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    tr_loss = []\n",
    "    pbar = tqdm(tr_dl)\n",
    "    for anchor_image, anchor_text, pos_image, pos_text, neg_image, neg_text in pbar:\n",
    "        \n",
    "        \n",
    "        anchor = anchor_image.to(device), {'input_ids' : anchor_text['input_ids'].to(device),\n",
    "                                           'attention_mask' : anchor_text['attention_mask'].to(device)}\n",
    "        \n",
    "        pos = pos_image.to(device), {'input_ids' : pos_text['input_ids'].to(device),\n",
    "                                     'attention_mask' : pos_text['attention_mask'].to(device)}\n",
    "        \n",
    "        neg = neg_image.to(device), {'input_ids' : neg_text['input_ids'].to(device),\n",
    "                                     'attention_mask' : neg_text['attention_mask'].to(device)}\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            anchor_emb = model(anchor)\n",
    "            pos_emb = model(pos)\n",
    "            neg_emb = model(neg)\n",
    "            loss = lf(anchor_emb, pos_emb, neg_emb)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        sched.step()\n",
    "        \n",
    "        tr_loss.append(loss.item())\n",
    "        pbar.set_description(f\"Train loss: {round(np.mean(tr_loss),3)}\")\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_dl)\n",
    "        for anchor_image, anchor_text, pos_image, pos_text, neg_image, neg_text in pbar:\n",
    "\n",
    "            anchor = anchor_image.to(device), {'input_ids' : anchor_text['input_ids'].to(device),\n",
    "                                               'attention_mask' : anchor_text['attention_mask'].to(device)}\n",
    "\n",
    "            pos = pos_image.to(device), {'input_ids' : pos_text['input_ids'].to(device),\n",
    "                                         'attention_mask' : pos_text['attention_mask'].to(device)}\n",
    "\n",
    "            neg = neg_image.to(device), {'input_ids' : neg_text['input_ids'].to(device),\n",
    "                                         'attention_mask' : neg_text['attention_mask'].to(device)}\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                \n",
    "                anchor_emb = model(anchor)\n",
    "                pos_emb = model(pos)\n",
    "                neg_emb = model(neg)\n",
    "                loss = lf(anchor_emb, pos_emb, neg_emb)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            pbar.set_description(f\"Val loss: {round(np.mean(val_loss),3)}\")\n",
    "            \n",
    "    tr_loss = round(np.mean(tr_loss),3)\n",
    "    val_loss = round(np.mean(val_loss),3)\n",
    "    tr_losses.append(tr_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    summary = f\"Ep {ep}: Train loss {tr_loss} - Val loss {val_loss}\"\n",
    "    print(summary) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '3ep.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91032c50ff3a40b3942b0411811cefbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embs = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(testing_dl)\n",
    "    for image, text in pbar:\n",
    "        x = image.to(device), {'input_ids' : text['input_ids'].to(device),\n",
    "                               'attention_mask' : text['attention_mask'].to(device)}\n",
    "        y = model(x)\n",
    "        embs.append(y.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.cat(embs,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_df = pd.DataFrame(embs.numpy())\n",
    "emb_cols = [f'emb_{i}' for i in embs_df.columns]\n",
    "embs_df.columns = emb_cols\n",
    "embs_df['cls'] = df['label_group']\n",
    "embs_df['cls'] = embs_df['cls'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>34240</th>\n",
       "      <th>34241</th>\n",
       "      <th>34242</th>\n",
       "      <th>34243</th>\n",
       "      <th>34244</th>\n",
       "      <th>34245</th>\n",
       "      <th>34246</th>\n",
       "      <th>34247</th>\n",
       "      <th>34248</th>\n",
       "      <th>34249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>emb_0</th>\n",
       "      <td>0.500960</td>\n",
       "      <td>0.237719</td>\n",
       "      <td>0.050669</td>\n",
       "      <td>0.718747</td>\n",
       "      <td>-0.581001</td>\n",
       "      <td>-0.097971</td>\n",
       "      <td>1.183702</td>\n",
       "      <td>1.779962</td>\n",
       "      <td>1.124665</td>\n",
       "      <td>-0.972785</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.564198</td>\n",
       "      <td>0.842688</td>\n",
       "      <td>-0.393273</td>\n",
       "      <td>-0.365358</td>\n",
       "      <td>-0.153456</td>\n",
       "      <td>-0.877197</td>\n",
       "      <td>0.058753</td>\n",
       "      <td>-0.112191</td>\n",
       "      <td>0.031476</td>\n",
       "      <td>0.074278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_1</th>\n",
       "      <td>-1.301394</td>\n",
       "      <td>-1.292176</td>\n",
       "      <td>-0.944553</td>\n",
       "      <td>-1.888656</td>\n",
       "      <td>-0.108013</td>\n",
       "      <td>-0.747545</td>\n",
       "      <td>-1.263595</td>\n",
       "      <td>-1.211068</td>\n",
       "      <td>-0.682983</td>\n",
       "      <td>0.179870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.576654</td>\n",
       "      <td>-0.905915</td>\n",
       "      <td>-0.449244</td>\n",
       "      <td>-0.466996</td>\n",
       "      <td>-0.804786</td>\n",
       "      <td>-0.308678</td>\n",
       "      <td>0.259296</td>\n",
       "      <td>-0.835542</td>\n",
       "      <td>-0.930508</td>\n",
       "      <td>-1.531453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_2</th>\n",
       "      <td>-0.226438</td>\n",
       "      <td>0.306056</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.311137</td>\n",
       "      <td>-0.544753</td>\n",
       "      <td>-0.013903</td>\n",
       "      <td>0.166399</td>\n",
       "      <td>0.306137</td>\n",
       "      <td>0.915265</td>\n",
       "      <td>-0.525376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455988</td>\n",
       "      <td>0.210848</td>\n",
       "      <td>-0.447949</td>\n",
       "      <td>-0.411966</td>\n",
       "      <td>0.376221</td>\n",
       "      <td>-0.085963</td>\n",
       "      <td>0.045716</td>\n",
       "      <td>0.809573</td>\n",
       "      <td>-0.265023</td>\n",
       "      <td>0.909191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_3</th>\n",
       "      <td>-0.323761</td>\n",
       "      <td>0.608568</td>\n",
       "      <td>-0.098363</td>\n",
       "      <td>-1.106508</td>\n",
       "      <td>0.221210</td>\n",
       "      <td>-1.320947</td>\n",
       "      <td>-0.539112</td>\n",
       "      <td>-1.217819</td>\n",
       "      <td>0.357320</td>\n",
       "      <td>-0.854563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597615</td>\n",
       "      <td>-0.977988</td>\n",
       "      <td>1.731781</td>\n",
       "      <td>1.720604</td>\n",
       "      <td>0.479843</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>0.526009</td>\n",
       "      <td>-0.228569</td>\n",
       "      <td>0.531991</td>\n",
       "      <td>0.439010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_4</th>\n",
       "      <td>-1.258861</td>\n",
       "      <td>-0.940595</td>\n",
       "      <td>0.709853</td>\n",
       "      <td>-0.407680</td>\n",
       "      <td>0.241497</td>\n",
       "      <td>-1.016383</td>\n",
       "      <td>-0.178965</td>\n",
       "      <td>-0.405246</td>\n",
       "      <td>0.401834</td>\n",
       "      <td>-0.620351</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.869939</td>\n",
       "      <td>-1.265399</td>\n",
       "      <td>-0.175623</td>\n",
       "      <td>-0.220973</td>\n",
       "      <td>-0.101543</td>\n",
       "      <td>-1.238433</td>\n",
       "      <td>-0.110854</td>\n",
       "      <td>-0.539160</td>\n",
       "      <td>0.548752</td>\n",
       "      <td>-1.179566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_124</th>\n",
       "      <td>1.327470</td>\n",
       "      <td>0.503480</td>\n",
       "      <td>0.680511</td>\n",
       "      <td>0.594233</td>\n",
       "      <td>-0.113412</td>\n",
       "      <td>-0.175654</td>\n",
       "      <td>0.622813</td>\n",
       "      <td>0.947124</td>\n",
       "      <td>0.934831</td>\n",
       "      <td>-0.190990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169104</td>\n",
       "      <td>0.302227</td>\n",
       "      <td>1.240302</td>\n",
       "      <td>1.217515</td>\n",
       "      <td>-0.716665</td>\n",
       "      <td>-0.396859</td>\n",
       "      <td>0.584340</td>\n",
       "      <td>-0.777377</td>\n",
       "      <td>0.648708</td>\n",
       "      <td>-0.493271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_125</th>\n",
       "      <td>-1.127460</td>\n",
       "      <td>-0.561340</td>\n",
       "      <td>0.595688</td>\n",
       "      <td>-0.708277</td>\n",
       "      <td>-0.253344</td>\n",
       "      <td>-1.247321</td>\n",
       "      <td>-0.849796</td>\n",
       "      <td>-1.481531</td>\n",
       "      <td>0.011094</td>\n",
       "      <td>-1.126404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344415</td>\n",
       "      <td>-0.091109</td>\n",
       "      <td>1.479870</td>\n",
       "      <td>1.414771</td>\n",
       "      <td>-0.354530</td>\n",
       "      <td>0.216521</td>\n",
       "      <td>-0.839207</td>\n",
       "      <td>-1.230204</td>\n",
       "      <td>0.316971</td>\n",
       "      <td>-1.293721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_126</th>\n",
       "      <td>0.465477</td>\n",
       "      <td>-1.320146</td>\n",
       "      <td>0.288588</td>\n",
       "      <td>0.464027</td>\n",
       "      <td>0.089630</td>\n",
       "      <td>-0.426252</td>\n",
       "      <td>-0.943907</td>\n",
       "      <td>0.281021</td>\n",
       "      <td>0.681009</td>\n",
       "      <td>0.782818</td>\n",
       "      <td>...</td>\n",
       "      <td>1.783656</td>\n",
       "      <td>0.248377</td>\n",
       "      <td>0.240647</td>\n",
       "      <td>0.235544</td>\n",
       "      <td>0.519699</td>\n",
       "      <td>-0.012075</td>\n",
       "      <td>0.809881</td>\n",
       "      <td>1.609108</td>\n",
       "      <td>-0.025901</td>\n",
       "      <td>-0.320838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emb_127</th>\n",
       "      <td>1.034373</td>\n",
       "      <td>-0.168213</td>\n",
       "      <td>-0.304716</td>\n",
       "      <td>-0.008191</td>\n",
       "      <td>0.086427</td>\n",
       "      <td>1.383384</td>\n",
       "      <td>0.928859</td>\n",
       "      <td>0.351101</td>\n",
       "      <td>0.364785</td>\n",
       "      <td>0.460414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302482</td>\n",
       "      <td>-0.573974</td>\n",
       "      <td>0.280889</td>\n",
       "      <td>0.266239</td>\n",
       "      <td>-0.264183</td>\n",
       "      <td>-0.374306</td>\n",
       "      <td>1.208320</td>\n",
       "      <td>-0.497938</td>\n",
       "      <td>-0.462315</td>\n",
       "      <td>0.550078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls</th>\n",
       "      <td>666.000000</td>\n",
       "      <td>7572.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>10509.000000</td>\n",
       "      <td>9425.000000</td>\n",
       "      <td>6836.000000</td>\n",
       "      <td>4687.000000</td>\n",
       "      <td>3976.000000</td>\n",
       "      <td>6076.000000</td>\n",
       "      <td>6754.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>8761.000000</td>\n",
       "      <td>9200.000000</td>\n",
       "      <td>9200.000000</td>\n",
       "      <td>7971.000000</td>\n",
       "      <td>9735.000000</td>\n",
       "      <td>7038.000000</td>\n",
       "      <td>10537.000000</td>\n",
       "      <td>4242.000000</td>\n",
       "      <td>1163.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows Ã— 34250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1            2             3            4      \\\n",
       "emb_0      0.500960     0.237719     0.050669      0.718747    -0.581001   \n",
       "emb_1     -1.301394    -1.292176    -0.944553     -1.888656    -0.108013   \n",
       "emb_2     -0.226438     0.306056     0.002641      0.311137    -0.544753   \n",
       "emb_3     -0.323761     0.608568    -0.098363     -1.106508     0.221210   \n",
       "emb_4     -1.258861    -0.940595     0.709853     -0.407680     0.241497   \n",
       "...             ...          ...          ...           ...          ...   \n",
       "emb_124    1.327470     0.503480     0.680511      0.594233    -0.113412   \n",
       "emb_125   -1.127460    -0.561340     0.595688     -0.708277    -0.253344   \n",
       "emb_126    0.465477    -1.320146     0.288588      0.464027     0.089630   \n",
       "emb_127    1.034373    -0.168213    -0.304716     -0.008191     0.086427   \n",
       "cls      666.000000  7572.000000  6172.000000  10509.000000  9425.000000   \n",
       "\n",
       "               5            6            7            8            9      ...  \\\n",
       "emb_0      -0.097971     1.183702     1.779962     1.124665    -0.972785  ...   \n",
       "emb_1      -0.747545    -1.263595    -1.211068    -0.682983     0.179870  ...   \n",
       "emb_2      -0.013903     0.166399     0.306137     0.915265    -0.525376  ...   \n",
       "emb_3      -1.320947    -0.539112    -1.217819     0.357320    -0.854563  ...   \n",
       "emb_4      -1.016383    -0.178965    -0.405246     0.401834    -0.620351  ...   \n",
       "...              ...          ...          ...          ...          ...  ...   \n",
       "emb_124    -0.175654     0.622813     0.947124     0.934831    -0.190990  ...   \n",
       "emb_125    -1.247321    -0.849796    -1.481531     0.011094    -1.126404  ...   \n",
       "emb_126    -0.426252    -0.943907     0.281021     0.681009     0.782818  ...   \n",
       "emb_127     1.383384     0.928859     0.351101     0.364785     0.460414  ...   \n",
       "cls      6836.000000  4687.000000  3976.000000  6076.000000  6754.000000  ...   \n",
       "\n",
       "              34240        34241        34242        34243        34244  \\\n",
       "emb_0     -1.564198     0.842688    -0.393273    -0.365358    -0.153456   \n",
       "emb_1     -0.576654    -0.905915    -0.449244    -0.466996    -0.804786   \n",
       "emb_2      0.455988     0.210848    -0.447949    -0.411966     0.376221   \n",
       "emb_3      0.597615    -0.977988     1.731781     1.720604     0.479843   \n",
       "emb_4     -0.869939    -1.265399    -0.175623    -0.220973    -0.101543   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "emb_124   -0.169104     0.302227     1.240302     1.217515    -0.716665   \n",
       "emb_125    0.344415    -0.091109     1.479870     1.414771    -0.354530   \n",
       "emb_126    1.783656     0.248377     0.240647     0.235544     0.519699   \n",
       "emb_127   -0.302482    -0.573974     0.280889     0.266239    -0.264183   \n",
       "cls      340.000000  8761.000000  9200.000000  9200.000000  7971.000000   \n",
       "\n",
       "               34245        34246         34247        34248        34249  \n",
       "emb_0      -0.877197     0.058753     -0.112191     0.031476     0.074278  \n",
       "emb_1      -0.308678     0.259296     -0.835542    -0.930508    -1.531453  \n",
       "emb_2      -0.085963     0.045716      0.809573    -0.265023     0.909191  \n",
       "emb_3       0.006830     0.526009     -0.228569     0.531991     0.439010  \n",
       "emb_4      -1.238433    -0.110854     -0.539160     0.548752    -1.179566  \n",
       "...              ...          ...           ...          ...          ...  \n",
       "emb_124    -0.396859     0.584340     -0.777377     0.648708    -0.493271  \n",
       "emb_125     0.216521    -0.839207     -1.230204     0.316971    -1.293721  \n",
       "emb_126    -0.012075     0.809881      1.609108    -0.025901    -0.320838  \n",
       "emb_127    -0.374306     1.208320     -0.497938    -0.462315     0.550078  \n",
       "cls      9735.000000  7038.000000  10537.000000  4242.000000  1163.000000  \n",
       "\n",
       "[129 rows x 34250 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_df.to_csv('train_embs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import functools\n",
    "from functools import partial\n",
    "import PIL\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DistilBertModel\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import EmbedorNN, Decidor\n",
    "from data_process import collate_fn, TripletDataset, create_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EmbedorNN().to(device)\n",
    "# weights: https://drive.google.com/drive/folders/19BGTC53p5YIAakWeCZfNIsceMX7cjHgp?usp=sharing\n",
    "model.load_state_dict(torch.load('data/3ep.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = 'data/train_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train val split\n",
    "labels = np.random.permutation(df['label_group'].unique())\n",
    "\n",
    "train_perc = 0.7\n",
    "train_idx = int(train_perc * len(labels))\n",
    "\n",
    "train_labels = labels[:train_idx]\n",
    "val_labels = labels[train_idx:]\n",
    "\n",
    "train_df = df[df['label_group'].isin(train_labels)]\n",
    "val_df = df[df['label_group'].isin(val_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                 std=(0.229, 0.224, 0.225))\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize((250, 250)),\n",
    "                                       transforms.ColorJitter(.25,.25,.25),\n",
    "                                       transforms.RandomRotation(5),\n",
    "                                       transforms.RandomCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       normalize\n",
    "                                       ])\n",
    "\n",
    "val_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     normalize\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dl = create_dl(images_path, train_df, train_transforms, shuffle = True)\n",
    "\n",
    "val_dl = create_dl(images_path, val_df, val_transforms, shuffle = False)\n",
    "\n",
    "testing_dl = create_dl(images_path, df, val_transforms, shuffle = False, testing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(testing_dl)\n",
    "    for image, text in pbar:\n",
    "        x = image.to(device), {'input_ids' : text['input_ids'].to(device),\n",
    "                               'attention_mask' : text['attention_mask'].to(device)}\n",
    "        y = model(x)\n",
    "        embs.append(y.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \n",
       "0                          Paper Bag Victoria Secret    249114794  \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045  \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891  \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188  \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-da8203e64896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embs' is not defined"
     ]
    }
   ],
   "source": [
    "embs = torch.cat(embs,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34250, 128])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(embs, 'embs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embs = torch.load('embs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassDS(Dataset) :\n",
    "    def __init__(self, embeddings, df, testing):\n",
    "        super(BinaryClassDS, self).__init__()\n",
    "        self.embeddings = embeddings\n",
    "        \n",
    "        self.testing = testing\n",
    "              \n",
    "        self.df = df.copy()\n",
    "        self.df['label_group'] = self.df['label_group'].astype('category').cat.codes\n",
    "        self.df['index'] = range(self.df.shape[0])\n",
    "        self.labels = self.df['label_group'].unique()\n",
    "        self.label_to_index_list = self.df.groupby('label_group')['index'].apply(list)\n",
    "        \n",
    "    def __getitem__(self, index) :\n",
    "        index_meta = self.df.iloc[index]\n",
    "        \n",
    "        anchor_emb = self.embeddings[index]\n",
    "            \n",
    "        label = index_meta['label_group']\n",
    "        \n",
    "        # positive sample\n",
    "        pos_index = random.choice(self.label_to_index_list[label])\n",
    "        # we don't want the positive sample being the same as the anchor\n",
    "        while pos_index == index :\n",
    "            pos_index = random.choice(self.label_to_index_list[label])\n",
    "        pos_emb = self.embeddings[pos_index]\n",
    "        \n",
    "        #negative sample\n",
    "        neg_label = random.choice(self.labels)\n",
    "        # Negative sample has to be different label from anchor \n",
    "        while neg_label == index :\n",
    "            neg_label = random.choice(self.labels)\n",
    "        neg_index = random.choice(self.label_to_index_list[neg_label])\n",
    "        neg_emb = self.embeddings[neg_index]\n",
    "        x = torch.stack([torch.cat([anchor_emb, pos_emb], dim=-1), \n",
    "                        torch.cat([anchor_emb, neg_emb], dim=-1)])\n",
    "        distances = [torch.dist(anchor_emb, pos_emb), torch.dist(anchor_emb, neg_emb)]\n",
    "        x = torch.cat([x, torch.stack(distances)[:, None]], dim=-1)\n",
    "        y = torch.tensor([1, 0])\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_binary(samples) :\n",
    "    x, y = zip(*samples)\n",
    "    x = torch.cat(x, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(BinaryClassDS(embs[list(train_df.index)], train_df, False), batch_size=124, shuffle=True, collate_fn=collate_fn_binary)\n",
    "val_dl = DataLoader(BinaryClassDS(embs[list(val_df.index)], val_df, False), batch_size=124, shuffle=False, collate_fn=collate_fn_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([248, 257]), torch.Size([248]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "_layers = []\n",
    "_layers.append(nn.Linear(128*2+1, 10))\n",
    "_layers.append(nn.BatchNorm1d(10))\n",
    "_layers.append(nn.ReLU())\n",
    "_layers.append(nn.Dropout(0.1))\n",
    "_layers.append(nn.Linear(10, 1))\n",
    "decidor = nn.Sequential(*_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b078bbbbf7a64524bc31447f9b5b7de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0280b5991894776bd5c596f270499be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=194.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc99cd160654fe3accb329accfdb769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=84.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ep 0: Train loss 0.491 - Val loss 0.193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308de10daf9d4cbfa31574c5de907a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=194.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c6ffa041094e17864cdc0cc90d4f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=84.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ep 1: Train loss 0.1 - Val loss 0.118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993ff417e5fd405eb0b4facbbcfc57c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=194.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfeb9e3461f4d10b6f1fab251da4e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=84.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ep 2: Train loss 0.067 - Val loss 0.107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a507c798d540de8b2a3afa49c95cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=194.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871c4a0a833148e68ac46f1810392049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=84.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ep 3: Train loss 0.064 - Val loss 0.086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6cc5ad2b6154bf1bec33af281d9f569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=194.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63e36e1309542988344334db561f6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=84.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ep 4: Train loss 0.058 - Val loss 0.086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70985f87d3748dba756e3b73d2a7ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=194.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4e939c045748fea598236db6eda555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=84.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ep 5: Train loss 0.056 - Val loss 0.085\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0ccda282e84faaaa5ae8848485ce86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=194.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d110adc68e4c27b4a006127bc8e602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=84.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ep 6: Train loss 0.055 - Val loss 0.085\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1452c6eb5346c1acd8d9ec03cd22b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=194.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd2e67c8f5f4bb6b4b1af08753dec57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=84.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ep 7: Train loss 0.054 - Val loss 0.084\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1aeae2a705d4c28a96d2bd3ef6eee4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=194.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d54865a9f404726bb0ac4d86a7c456c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=84.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ep 8: Train loss 0.051 - Val loss 0.084\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b308c4001994955a8176667cd00fb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=194.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab8679b4ad6485face6b875dbe1ec16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=84.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ep 9: Train loss 0.049 - Val loss 0.085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "swa_start = int(0.75*n_epochs)\n",
    "\n",
    "s = nn.Sigmoid()\n",
    "lf = nn.BCELoss()\n",
    "\n",
    "lr = 1e-2\n",
    "wd = 0\n",
    "\n",
    "optimizer = torch.optim.AdamW(decidor.parameters(), lr=lr)\n",
    "\n",
    "# learning rate scheduler\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr =lr, pct_start = 0.3, #anneal_strategy = 'linear',\n",
    "                                            total_steps = int(n_epochs * len(train_dl)))\n",
    "\n",
    "\n",
    "tr_losses = []\n",
    "val_losses = []\n",
    "for ep in tqdm(range(n_epochs)):\n",
    "    decidor.train()\n",
    "    tr_loss = []\n",
    "    pbar = tqdm(train_dl)\n",
    "    for x, y in pbar:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = s(decidor(x)).squeeze() \n",
    "        loss = lf(y_pred, y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sched.step()\n",
    "        \n",
    "        tr_loss.append(loss.item())\n",
    "        pbar.set_description(f\"Train loss: {round(np.mean(tr_loss),3)}\")\n",
    "        \n",
    "    decidor.eval()\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_dl)\n",
    "        for x, y in pbar:\n",
    "            y_pred = s(decidor(x)).squeeze()\n",
    "            loss = lf(y_pred, y.float())\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            pbar.set_description(f\"Val loss: {round(np.mean(val_loss),3)}\")\n",
    "            \n",
    "    tr_loss = round(np.mean(tr_loss),3)\n",
    "    val_loss = round(np.mean(val_loss),3)\n",
    "    tr_losses.append(tr_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    summary = f\"Ep {ep}: Train loss {tr_loss} - Val loss {val_loss}\"\n",
    "    print(summary) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47aeeb2b5f364fc3bec5b4bc6ecaaede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=84.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9735)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    acc = 0\n",
    "    pbar = tqdm(val_dl)\n",
    "    for x, y in pbar:\n",
    "        y_pred = s(decidor(x)).squeeze() > 0.5\n",
    "        acc += (y_pred==y).float().mean()\n",
    "acc/len(val_dl)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(decidor.state_dict(), 'data/3ep_decidor.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
