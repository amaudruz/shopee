{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import functools\n",
    "from functools import partial\n",
    "import PIL\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMaxDS(Dataset):\n",
    "    def __init__(self, data, images_path, return_triplet = True):\n",
    "        super().__init__()\n",
    "        self.imgs = data['image'].tolist()\n",
    "        self.unique_labels = data['label_group'].unique().tolist()\n",
    "        self.labels = data['label_group'].astype('category')\n",
    "        self.label_codes = self.labels.cat.codes\n",
    "        \n",
    "        self.images_path = images_path\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = self._get_item(idx)\n",
    "        label = self.label_codes.iloc[idx]\n",
    "        return img, label\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def _get_item(self, idx):\n",
    "        im = PIL.Image.open(os.path.join(self.images_path, self.imgs[idx]))\n",
    "        im = torch.tensor(np.array(im) / 255.0, dtype = torch.float).permute(2,0,1)\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "\n",
    "df = pd.read_csv('data/train.csv')\n",
    "small_images_dir = 'data/small_train_images/'\n",
    "n_classes = df['label_group'].nunique()\n",
    "np.random.seed(1337)\n",
    "\n",
    "# train val split\n",
    "\n",
    "train_perc = 0.7\n",
    "n_train_examples = int(train_perc * len(df))\n",
    "\n",
    "train_df = df.iloc[:n_train_examples]\n",
    "val_df = df.iloc[n_train_examples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataloaders\n",
    "\n",
    "vision_model = 'resnet50'\n",
    "\n",
    "bs = 64\n",
    "tr_ds = SoftMaxDS(df, small_images_dir)\n",
    "tr_dl = DataLoader(tr_ds, batch_size = bs, shuffle = True, pin_memory = True)\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMBCLass(nn.Module) :\n",
    "    def __init__(self, pretrained_image_embedor='resnet50',\n",
    "                output_dim=512) :\n",
    "        super(EMBCLass, self).__init__()\n",
    "        self.image_embedor = timm.create_model(pretrained_image_embedor, pretrained=True)\n",
    "        self.image_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.head = nn.Sequential(nn.Linear(2048, output_dim), \n",
    "                                  #nn.ReLU(),\n",
    "                                  )\n",
    "        \n",
    "        for m in self.head.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                sz = m.weight.data.size(-1)\n",
    "                m.weight.data.normal_(mean=0.0, std=1/np.sqrt(sz))\n",
    "            elif isinstance(m, (nn.LayerNorm, nn.BatchNorm1d)):\n",
    "                m.bias.data.zero_()\n",
    "                m.weight.data.fill_(1.0)\n",
    "                m.bias.data.zero_()\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "    def _get_embs(self, x) :\n",
    "        images = x\n",
    "        out_images = self.image_embedor.forward_features(images)\n",
    "        out_images = self.image_pool(out_images).squeeze()\n",
    "        #return F.normalize(out_images, dim=-1)\n",
    "        return out_images\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        out_images = self._get_embs(x)\n",
    "        \n",
    "        return self.head(out_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EMBCLass(vision_model, output_dim=n_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalize = transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                 std=(0.229, 0.224, 0.225))\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.ColorJitter(.3,.3,.3),\n",
    "                                       transforms.RandomRotation(5),\n",
    "                                       transforms.RandomCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       normalize\n",
    "                                       ])\n",
    "\n",
    "val_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                     normalize\n",
    "                                     ])\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "lf = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 1e-2\n",
    "wd = 0\n",
    "no_decay = [\"bias\", \"BatchNorm2d.weight\", \"BatchNorm2d.bias\", \"LayerNorm.weight\", 'LayerNorm.bias',\n",
    "            \"BatchNorm1d.weight\", \"BatchNorm1d.bias\"]\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": wd,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in  model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "\n",
    "# learning rate scheduler\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr =lr, pct_start = 0.3, #anneal_strategy = 'linear',\n",
    "                                            total_steps = int(n_epochs * len(tr_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ffc0e44aa24b4d97c378cacda54d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27daf444aec649f5b970b53cac271316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=536.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_losses = []\n",
    "val_losses = []\n",
    "for ep in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    tr_loss = []\n",
    "    pbar = tqdm(tr_dl)\n",
    "    for imgs, labels in pbar:\n",
    "        \n",
    "        imgs = train_transforms(imgs.to(device))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs)\n",
    "        loss = lf(out, labels.long().to(device))\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sched.step()\n",
    "        \n",
    "        tr_loss.append(loss.item())\n",
    "        pbar.set_description(f\"Train loss: {round(np.mean(tr_loss),3)}\")\n",
    "    \n",
    "    if ep%2==0 :\n",
    "        torch.save(model.state_dict(), 'data/tests_model_image/model_class_ep_{}.pth'.format(ep))\n",
    "    model.eval()\n",
    "    tr_losses.append(tr_loss)\n",
    "    summary = f\"Ep {ep}: Train loss {tr_loss}\"\n",
    "    print(summary) \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
